---
title: "mycoBinR"
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# mycoBinR

<!-- badges: start -->
<!-- badges: end -->

**mycoBinR** helps you organize pipeline file paths and build tidy, analysis-ready tables for fungal/metagenome assemblies. It integrates contig metrics (coverage, GC, BUSCO, taxonomy), parses telomeres, refines consensus taxonomy using read-connection “bubbles”, and exports per-taxon **FASTA**/**BED** bins.

This README is written in the style of the [*r-pkgs*](https://r-pkgs.org/) website: short motivation, reproducible examples, and clear function sections.

---

## Installation

You can install the development version of **mycoBinR** from GitHub:

```r
# install.packages("devtools")
devtools::install_github("taui11/mycoBinR")
```

---

## Example

The `create_filepaths_df()` function builds a data frame listing file names and absolute paths for a given project directory, project number, and title. This *paths index* is used by the downstream functions.

```{r example}
library(mycoBinR)

filepaths <- create_filepaths_df(
  base_path = "/project/data_output",
  project_nr = "pr_01_",
  TITLE     = "001"
)
print(filepaths)
```

---

## Function index

| Function | Purpose | Typical key inputs | Output |
|---|---|---|---|
| `create_filepaths_df()` | Declaratively define where pipeline outputs live. | `base_path`, `project_nr`, `TITLE` | tibble with `name`, `path` |
| `build_contig_table()` | Assemble a master contig table (coverage, GC, BUSCO, taxonomy, clustering). | `paths_df`, `api_key` (optional) | data frame, one row per contig |
| `parse_telomeres()` | Parse left/right telomere motifs; classify completeness. | `DATA`, `paths_df` | telomere annotations per contig |
| `incorporate_bam_bubbles()` | Use supplementary read connections to refine `tax_cons`. | `DATA`, `telomeres`, `paths_df` | updated contig table |
| `export_binned()` | Write per-taxon FASTA and BED files. | `DATA`, `paths_df`, `SAMPLE` | files on disk |

---

## Typical workflow

```{r, eval = FALSE}
library(mycoBinR)

# 1) Describe your pipeline outputs (only once per sample/run)
paths_df <- create_filepaths_df(
  base_path  = "/project/data_output",
  project_nr = "pr_01_",
  TITLE      = "001"
)

# 2) Build the contig-level table (coverage, GC, BUSCO, taxonomy, clustering)
DATA <- build_contig_table(paths_df, api_key = Sys.getenv("ENTREZ_KEY"))

# 3) Parse telomere motif calls and classify completeness
telos <- parse_telomeres(DATA, paths_df)

# 4) Refine consensus taxonomy using read-connection “bubbles”
DATA2 <- incorporate_bam_bubbles(DATA, telos, paths_df)

# 5) Export taxon-specific FASTA and BED bins
export_binned(DATA2, paths_df, SAMPLE = "001")
```

---

## `build_contig_table()`

Build a *single*, tidy table with one row per contig, combining assembly metrics, GC %, coverage summaries, BUSCO counts, and taxonomy. Optionally supply an Entrez API key to avoid rate limits.

```{r, eval = FALSE}
DATA <- build_contig_table(
  paths_df,
  api_key = Sys.getenv("ENTREZ_KEY")  # optional but recommended
)

# Glimpse key columns (if present)
subset_cols <- c(
  "contig", "length", "gc", "cov_mean",
  "busco_complete", "tax_raw", "tax_cons"
)
print(DATA[intersect(names(DATA), subset_cols)])
```

**Inputs**

- `paths_df`: from `create_filepaths_df()`, must point to assembly, coverage, BUSCO, taxonomy outputs, etc.  
- `api_key`: optional NCBI Entrez key for stable taxonomy lookups.

**Output**

- Data frame with per-contig metrics and taxonomic fields (e.g., `tax_raw`, `tax_cons`).

---

## `parse_telomeres()`

Parse left/right telomere motif hits and classify telomere completeness for each contig.

```{r, eval = FALSE}
telos <- parse_telomeres(
  DATA,
  paths_df
)

head(telos)
# dplyr::count(telos, telomere_class)
```

**Expected columns (typical)**  
`contig`, `leftmotif`, `leftscore`, `rightmotif`, `rightrc`, `rightscore`, `telomere_class`.

---

## `incorporate_bam_bubbles()`

Use supplementary alignments (from your BAM) to find connected contig “bubbles” and propagate/refine `tax_cons` across those connections.

```{r, eval = FALSE}
DATA2 <- incorporate_bam_bubbles(
  DATA,
  telomeres = telos,
  paths_df  = paths_df
)

# Inspect changes in consensus taxonomy
# dplyr::count(DATA$tax_cons)  |> dplyr::arrange(desc(n))
# dplyr::count(DATA2$tax_cons) |> dplyr::arrange(desc(n))
```

**Notes**

- Ensure your mapper emitted *supplementary alignments*; otherwise connectivity may be sparse.  
- `paths_df` must reference the correct BAM and any required indices.

---

## `export_binned()`

Export one **FASTA** and one **BED** per **taxonomic bin**. Filenames usually include your `SAMPLE` tag.

```{r, eval = FALSE}
export_binned(
  DATA2,
  paths_df,
  SAMPLE = "001"  # appears in output filenames
)

# After running, inspect output directories referenced in paths_df
# (e.g., fasta_folder, bed_folder).
```

**Side effects**

- Writes files to disk; no return value. Designed for downstream visualization and analysis.

---

## Troubleshooting

- **File not found**: print `paths_df` and confirm every expected `name` has a valid `path`.  
- **Taxonomy rate limits**: set `ENTREZ_KEY` in your shell profile (or within R) before running `build_contig_table()`.  
- **No effect from bubbles**: verify BAM has supplementary alignments; double-check `paths_df` entries for BAM/index.  
- **Reproducibility**: keep your directory layout stable so `create_filepaths_df()` can infer paths consistently.

---

## Session info

```{r}
sessionInfo()
```

